{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing with the model (4), we numerically investigate the performance of various estimators designed for static panel data models, namely, $\\hat\\beta_{n,\\mathrm{POLS}}$, $\\hat\\beta_{n,\\mathrm{FE}}$, $\\hat\\beta_{n,\\mathrm{FD}}$, and the first differenced estimator using $Y_{i,t-2}$ as instrument (i.e., the IV estimator of $\\beta_0$ for the first-differenced equation using $Y_{i,t-2}$ as instrument). First, for each triple $(n,T,\\beta_0)$ to be specified shortly, obtain the sample as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Simulate $\\alpha_i\\overset{\\mathrm{iid}}{\\sim} N(0,1)$ and $\\epsilon_i\\overset{\\mathrm{iid}}{\\sim} N(0,1)$.\n",
    "\n",
    "2. Generate $Y_{i0}$ according to $Y_{i0}=0.5\\alpha_i + \\epsilon_i$.\n",
    "\n",
    "3. Generate $Y_{it}$ according to (4) with $V_{it}\\overset{\\mathrm{iid}}{\\sim} N(0,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may then compute the aforementioned estimators with the generated sample. Repeat the above steps $1000$ times, let $\\hat\\beta^{(r)}$ be the estimate based on the $i$th replication (for a particular estimator), and then the finite sample bias, standard error and root mean squared error are computed as follows:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathrm{Bias}(\\hat\\beta)&=\\frac{1}{1000}\\sum_{r=1}^{1000}\\hat\\beta^{(r)} - \\beta_0~,\\\\\n",
    "    \\mathrm{SE}(\\hat\\beta)&=\\{\\frac{1}{1000}\\sum_{r=1}^{1000}(\\hat\\beta^{(r)}-\\frac{1}{1000}\\sum_{r=1}^{1000}\\hat\\beta^{(r)})^2 \\}^{1/2}~,\\\\\n",
    "    \\mathrm{RMSE} (\\hat\\beta) & = \\{[\\mathrm{Bias}(\\hat\\beta)]^2 + [\\mathrm{SE}(\\hat\\beta)]^2\\}^{1/2}~.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Let $n=100$ and $T=6$. Graph the bias, se and rmse of each estimator as functions of $\\beta_0\\in\\{0,0.25,0.5,0.75,1\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import linearmodels.panel as lm\n",
    "\n",
    "def DGP(n,T,b0 = 0.5):\n",
    "    a = np.random.normal(0,1,n)\n",
    "    e = np.random.normal(0,1,n)\n",
    "    \n",
    "    Y0 = 0.5*a + e  # n by 1\n",
    "    Ymatrix = np.zeros([n, T])  # n by T then stack\n",
    "    Xmatrix = np.zeros([n, T])\n",
    "    for t in range(T):\n",
    "        V = np.random.normal(0,1,n)\n",
    "        if t == 0:\n",
    "            Y1 = b0*Y0 + a + V\n",
    "            Ymatrix[:,t] = Y1\n",
    "            Xmatrix[:,t] = Y0\n",
    "        else:\n",
    "            Y0 = Ymatrix[:,t-1]\n",
    "            Y1 = b0*Y0 + a + V\n",
    "            Ymatrix[:,t] = Y1\n",
    "            Xmatrix[:,t] = Y0\n",
    "    \n",
    "    Y = Ymatrix.reshape(-1)\n",
    "    X = Xmatrix.reshape(-1)\n",
    "    i = np.kron(np.array([i+1 for i in range(n)]).reshape(n,1), np.ones(T).reshape(T,1)).reshape(-1)\n",
    "    t = np.kron(np.ones(n).reshape(n,1), np.array([i+1 for i in range(T)]).reshape(T,1)).reshape(-1)\n",
    "    df = pd.DataFrame({'i':i,'t':t,'Y':Y,'X':X})\n",
    "    \n",
    "    return df\n",
    "\n",
    "def test_DGP(n,T,b0 = 0.5):\n",
    "    \"\"\"\n",
    "    X is exogenous\n",
    "    \"\"\"\n",
    "    a = np.random.normal(0,1,n)\n",
    "    e = np.random.normal(0,1,n)\n",
    "    \n",
    "    Y0 = 0.5*a + e  # n by 1\n",
    "    Ymatrix = np.zeros([n, T])  # n by T -> stack using reshape.\n",
    "    Xmatrix = np.zeros([n, T])\n",
    "    for t in range(T):\n",
    "        V = np.random.normal(0,1,n)\n",
    "        X = np.random.normal(0,1,n)\n",
    "        Y = b0 * X + a + V        \n",
    "        Ymatrix[:,t] = Y\n",
    "        Xmatrix[:,t] = X\n",
    "    Y = Ymatrix.reshape(-1)\n",
    "    X = Xmatrix.reshape(-1)\n",
    "    i = np.kron(np.array([i+1 for i in range(n)]).reshape(n,1), np.ones(T).reshape(T,1)).reshape(-1)\n",
    "    t = np.kron(np.ones(n).reshape(n,1), np.array([i+1 for i in range(T)]).reshape(T,1)).reshape(-1)\n",
    "    df = pd.DataFrame({'i':i,'t':t,'Y':Y,'X':X})\n",
    "    \n",
    "    return df\n",
    "\n",
    "def my_OLS(Y,X):\n",
    "    beta = np.linalg.inv(X.T@X) @ (X.T@Y)\n",
    "    \n",
    "    return beta[0]\n",
    "\n",
    "def my_FE(Y,X,T):\n",
    "    nT, k = X.shape\n",
    "    n = int(nT/T)\n",
    "    Qi = np.eye(T) - (np.ones(T).reshape(T,1) @ np.ones(T).reshape(1,T))/T\n",
    "    Q = np.kron(np.eye(n), Qi)\n",
    "    \n",
    "    beta = np.linalg.inv(X.T @ Q @ X) @ (X.T @ Q @ Y)\n",
    "    \n",
    "    return beta[0]\n",
    "\n",
    "def my_FD(Y,X,T):\n",
    "    nT,k = X.shape\n",
    "    n = int(nT/T)\n",
    "    \n",
    "    toep = toeplitz([-1,*np.zeros(T-2)],[0,1,*np.zeros(T-2)])\n",
    "    dY = np.kron(np.eye(n),toep) @ Y\n",
    "    dX = np.kron(np.eye(n),toep) @ X\n",
    "    \n",
    "    beta = my_OLS(dY,dX)\n",
    "    return beta[0]\n",
    "\n",
    "def my_FD_IV(Y,X,T, method=\"2SLS\"):\n",
    "    nT,k = X.shape\n",
    "    n = int(nT/T)\n",
    "    \n",
    "    toep = toeplitz([-1,*np.zeros(T-2)],[0,1,*np.zeros(T-2)])[1:,:]\n",
    "    dY = np.kron(np.eye(n),toep) @ Y\n",
    "    dX = np.kron(np.eye(n),toep) @ X\n",
    "    \n",
    "    sel = np.eye(T)[:-2,:]\n",
    "    Z = np.kron(np.eye(n),sel) @ Y\n",
    "    \n",
    "#     Y_nbyT = Y.reshape(n, T)  # [Y_{t=1}, Y_{t=2}, ..., Y_{t=T}]\n",
    "#     X_nbyT = X.reshape(n, T)\n",
    "#     Y_nbyT_lag = np.column_stack([np.zeros(n), Y_nbyT[:,:-1]])  # [0,t=2-1,t=3-2,...]\n",
    "#     X_nbyT_lag = np.column_stack([np.zeros(n), X_nbyT[:,:-1]])\n",
    "    \n",
    "#     dY = (Y_nbyT-Y_nbyT_lag)[:,2:].reshape([n*(T-2),1])  # vec[Y_{t=3-2}, Y_{t=4-3}, ...]\n",
    "#     dX = (X_nbyT-X_nbyT_lag)[:,2:].reshape([n*(T-2),k])  # vec[Y_{t=2-1}, Y_{t=3-2}, ...]\n",
    "#     iv = Y_nbyT[:,:-2].reshape([n*(T-2),1])  # vec[Y_{t=1}, Y_{t=2}, ..., Y_{t=T-2}]\n",
    "    \n",
    "    # 2SLS\n",
    "    if method == \"2SLS\":\n",
    "        dXhat = Z @ (np.linalg.inv(Z.T@Z) @ (Z.T@dX))\n",
    "        beta = my_OLS(dY,dXhat)\n",
    "    if method == \"IV\":\n",
    "        nom = dX.T@Z @ np.linalg.inv(Z.T@Z) @ Z.T@dY\n",
    "        denom = dX.T@Z @ np.linalg.inv(Z.T@Z) @ Z.T@dX\n",
    "        beta = np.linalg.inv(denom) @ nom\n",
    "        beta = beta[0]\n",
    "    if method == \"IV_just\":\n",
    "        beta = np.linalg.inv(Z.T@dX) @ Z.T@dY\n",
    "\n",
    "    return beta\n",
    "\n",
    "def simulation_Q3(n,T,M=1000,test=False):\n",
    "    res = []\n",
    "    for b0 in [0, 0.25, 0.5, 0.75, 1]:\n",
    "        res_POLS = np.zeros(M)\n",
    "        res_FE = np.zeros(M)\n",
    "        res_FD = np.zeros(M)\n",
    "        res_FD_IV = np.zeros(M)\n",
    "    \n",
    "        for m in range(M):\n",
    "            if test is True:\n",
    "                df = test_DGP(n=n,T=T,b0=b0)\n",
    "                Y = np.array(df.Y).reshape(n*T,1)\n",
    "                X = np.array(df.X).reshape(n*T,1)\n",
    "            else:\n",
    "                df = DGP(n=n,T=T,b0=b0)\n",
    "                Y = np.array(df.Y).reshape(n*T,1)\n",
    "                X = np.array(df.X).reshape(n*T,1)\n",
    "            res_POLS[m] = my_OLS(Y,X)\n",
    "            res_FE[m] = my_FE(Y,X,T=T)\n",
    "            res_FD[m] = my_FD(Y,X,T=T)\n",
    "            res_FD_IV[m] = my_FD_IV(Y,X,T=T,method=\"2SLS\")\n",
    "    \n",
    "        res.append({\"POLS\":res_POLS, \"FE\":res_FE,\"FD\":res_FD,\"FD_IV\":res_FD_IV})\n",
    "    return res\n",
    "\n",
    "def figure_Q3(res, n, T, save=False):\n",
    "    b0 = np.array([0,0.25,0.5,0.75,1.])\n",
    "    result_000 = res[0]\n",
    "    \n",
    "    result_000_POLS = result_000[\"POLS\"]\n",
    "    \n",
    "    result_025 = res[1]\n",
    "    result_050 = res[2]\n",
    "    result_075 = res[3]\n",
    "    result_100 = res[4]\n",
    "          \n",
    "    bias_POLS = [res[i][\"POLS\"].mean() - b0[i] for i in range(len(res))]\n",
    "    bias_FE = [res[i][\"FE\"].mean() - b0[i] for i in range(len(res))]\n",
    "    bias_FD = [res[i][\"FD\"].mean() - b0[i] for i in range(len(res))]\n",
    "    bias_FD_IV = [res[i][\"FD_IV\"].mean() - b0[i] for i in range(len(res))]\n",
    "\n",
    "    std_POLS = [res[i][\"POLS\"].std() for i in range(len(res))]\n",
    "    std_FE = [res[i][\"FE\"].std() for i in range(len(res))]\n",
    "    std_FD = [res[i][\"FD\"].std() for i in range(len(res))]\n",
    "    std_FD_IV = [res[i][\"FD_IV\"].std() for i in range(len(res))]\n",
    "    \n",
    "    rmse_POLS = [np.sqrt(bias_POLS[i]**2 + std_POLS[i]**2) for i in range(len(res))]\n",
    "    rmse_FE = [np.sqrt(bias_FE[i]**2 + std_FE[i]**2) for i in range(len(res))]\n",
    "    rmse_FD = [np.sqrt(bias_FD[i]**2 + std_FD[i]**2) for i in range(len(res))]\n",
    "    rmse_FD_IV = [np.sqrt(bias_FD_IV[i]**2 + std_FD_IV[i]**2) for i in range(len(res))]\n",
    "    \n",
    "    fig, ax = plt.subplots(1,3,figsize = (21,4))\n",
    "    \n",
    "    ax[0].plot(b0, bias_POLS)\n",
    "    ax[0].plot(b0, bias_FE)\n",
    "    ax[0].plot(b0, bias_FD)\n",
    "    ax[0].plot(b0, bias_FD_IV)\n",
    "    ax[0].axhline(0, color='black')\n",
    "    ax[0].legend([\"POLS\", \"FE\", \"FD\", \"FD_IV\"])\n",
    "    ax[0].set_xlabel('b0')\n",
    "    ax[0].set_title(\"Bias of simulation (n={},T={})\".format(n,T))\n",
    "\n",
    "    ax[1].plot(b0, std_POLS)\n",
    "    ax[1].plot(b0, std_FE)\n",
    "    ax[1].plot(b0, std_FD)\n",
    "    ax[1].plot(b0, std_FD_IV)\n",
    "    ax[1].legend([\"POLS\", \"FE\", \"FD\", \"FD_IV\"])\n",
    "    ax[1].set_xlabel('b0')\n",
    "    ax[1].set_title(\"SE of simulation (n={},T={})\".format(n,T))\n",
    "\n",
    "    ax[2].plot(b0, rmse_POLS)\n",
    "    ax[2].plot(b0, rmse_FE)\n",
    "    ax[2].plot(b0, rmse_FD)\n",
    "    ax[2].plot(b0, rmse_FD_IV)\n",
    "    ax[2].legend([\"POLS\", \"FE\", \"FD\", \"FD_IV\"])\n",
    "    ax[2].set_xlabel('b0')\n",
    "    ax[2].set_title(\"RMSE of simulation (n={},T={})\".format(n,T))\n",
    "    \n",
    "    fig.savefig('fig_n{}_T{}.jpg'.format(n,T), dpi=80)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_n100_T6 = simulation_Q3(n=100,T=6,M=1000)\n",
    "fig_n100_T6 = figure_Q3(results_n100_T6, n=100,T=6, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 . Repeat part (1) with $(n,T)=(100,3)$ and $(n,T)=(100,9)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,T = 100,3\n",
    "results_n100_T3 = simulation_Q3(n=n,T=T,M=1000)\n",
    "fig_n100_T3 = figure_Q3(results_n100_T3, n=n,T=T, save=True)\n",
    "\n",
    "n,T = 100,9\n",
    "results_n100_T9 = simulation_Q3(n=n,T=T,M=1000)\n",
    "fig_n100_T9 = figure_Q3(results_n100_T9, n=n,T=T, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydynpd import regression\n",
    "_data = test_DGP(n=100,T=6,b0=0.5)\n",
    "command_str='Y L1.Y  | gmm(Y, 2:.) | nolevel'\n",
    "mydpd = regression.abond(command_str, _data, ['i', 't'])\n",
    "\n",
    "mydpd.models[0].regression_table.coefficient[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = DGP(100,6,0)\n",
    "_Y = np.array(_data.Y).reshape(600,1)\n",
    "_X = np.array(_data.X).reshape(600,1)\n",
    "\n",
    "np.column_stack([_Y,_X])\n",
    "\n",
    "my_FD_IV(_Y,_X,T=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do Exercise 17.17(a) in Hansen (2022). You will need the formula (17.93) in Hansen (2022) (see the pdf file in Canvas) for the clustered standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip</th>\n",
       "      <th>year</th>\n",
       "      <th>pstar</th>\n",
       "      <th>z0</th>\n",
       "      <th>pricef</th>\n",
       "      <th>divf</th>\n",
       "      <th>rnda</th>\n",
       "      <th>adva</th>\n",
       "      <th>fyr</th>\n",
       "      <th>ardsic</th>\n",
       "      <th>...</th>\n",
       "      <th>debta</th>\n",
       "      <th>sales</th>\n",
       "      <th>netcap</th>\n",
       "      <th>earnsh</th>\n",
       "      <th>nyseamex</th>\n",
       "      <th>h0</th>\n",
       "      <th>h1</th>\n",
       "      <th>vala</th>\n",
       "      <th>oneper</th>\n",
       "      <th>sharef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>1970</td>\n",
       "      <td>4.45946</td>\n",
       "      <td>31.21624</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04644</td>\n",
       "      <td>45.33499</td>\n",
       "      <td>22.64583</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1</td>\n",
       "      <td>53.51015</td>\n",
       "      <td>19.18859</td>\n",
       "      <td>1.17240</td>\n",
       "      <td>-0.48167</td>\n",
       "      <td>2655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>1971</td>\n",
       "      <td>5.18880</td>\n",
       "      <td>31.13281</td>\n",
       "      <td>5.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.66158</td>\n",
       "      <td>47.03299</td>\n",
       "      <td>19.28410</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>1</td>\n",
       "      <td>54.77370</td>\n",
       "      <td>16.40725</td>\n",
       "      <td>0.79165</td>\n",
       "      <td>-0.19062</td>\n",
       "      <td>2655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>1972</td>\n",
       "      <td>5.66540</td>\n",
       "      <td>28.32700</td>\n",
       "      <td>5.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00543</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57597</td>\n",
       "      <td>34.36200</td>\n",
       "      <td>14.90893</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>52.25176</td>\n",
       "      <td>12.75835</td>\n",
       "      <td>0.91267</td>\n",
       "      <td>-0.694</td>\n",
       "      <td>2655.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cusip  year    pstar        z0  pricef  divf  rnda     adva  fyr  ardsic  \\\n",
       "0     32  1970  4.45946  31.21624  10.000   0.0   0.0  0.00000   12      11   \n",
       "1     32  1971  5.18880  31.13281   5.750   0.0   0.0  0.00000   12      11   \n",
       "2     32  1972  5.66540  28.32700   5.125   0.0   0.0  0.00543   12      11   \n",
       "\n",
       "   ...    debta     sales    netcap  earnsh  nyseamex        h0        h1  \\\n",
       "0  ...  0.04644  45.33499  22.64583    0.17         1  53.51015  19.18859   \n",
       "1  ...  0.66158  47.03299  19.28410   -0.65         1  54.77370  16.40725   \n",
       "2  ...  0.57597  34.36200  14.90893    0.72         1  52.25176  12.75835   \n",
       "\n",
       "      vala    oneper  sharef  \n",
       "0  1.17240  -0.48167  2655.0  \n",
       "1  0.79165  -0.19062  2655.0  \n",
       "2  0.91267    -0.694  2655.0  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "import pandas as pd\n",
    "from pydynpd import regression\n",
    "file = os.path.join(os.getcwd(),\"..\",\"Econometrics Data\",\"Invest1993\",\"Invest1993.txt\")\n",
    "df = pd.read_csv(file, sep='\\t')\n",
    "df.head(3)\n",
    "#df.year.unique().max() - df.year.unique().min() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "D_{it} = \\alpha D_{i,t-1} + u_i + \\epsilon_{it}\n",
    "$$\n",
    "\n",
    "(a) Estimate the model using Arellano-Bond twostep GMM with clustered se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dynamic panel-data estimation, two-step difference GMM\n",
      " Group variable: cusip                             Number of obs = 23642    \n",
      " Time variable: year                               Min obs per group: 3     \n",
      " Number of instruments = 465                       Max obs per group: 30    \n",
      " Number of groups = 1962                           Avg obs per group: 12.05 \n",
      "+----------+-----------+---------------------+------------+-----------+-----+\n",
      "|  debta   |   coef.   | Corrected Std. Err. |     z      |   P>|z|   |     |\n",
      "+----------+-----------+---------------------+------------+-----------+-----+\n",
      "| L1.debta | 0.5754460 |      0.0565248      | 10.1804141 | 0.0000000 | *** |\n",
      "+----------+-----------+---------------------+------------+-----------+-----+\n",
      "Hansen test of overid. restrictions: chi(464) = 510.883 Prob > Chi2 = 0.065\n",
      "Arellano-Bond test for AR(1) in first differences: z = -4.21 Pr > z =0.000\n",
      "Arellano-Bond test for AR(2) in first differences: z = 1.21 Pr > z =0.226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "command_str='debta L1.debta  | gmm(debta, 2:.) | nolevel'\n",
    "mydpd = regression.abond(command_str, df, ['cusip', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import janitor\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "df = pd.read_csv(file, sep='\\t')\n",
    "\n",
    "#def my_Arellano_Bond(data):\n",
    "exog = ['debta']\n",
    "endog = ['L1.debta']\n",
    "iv = ['L2.debta']\n",
    "ID = 'cusip'\n",
    "T = 'year'\n",
    "\n",
    "data = df[['cusip','year','debta']].copy()\n",
    "data = data.sort_values([ID,T])\n",
    "Tmax = np.max(data.groupby('cusip').year.count())\n",
    "\n",
    "# generate lagged variables\n",
    "for name in [*endog,*iv]:\n",
    "    if name.split('.')[0] == 'L1':  # assume T increases by 1\n",
    "        data[name] = data[[ID, name.split('.')[-1]]].groupby(ID).shift(1)\n",
    "    if name.split('.')[0] == 'L2':\n",
    "        data[name] = data[[ID, name.split('.')[-1]]].groupby(ID).shift(2)\n",
    "        \n",
    "# generate differenced varialbes\n",
    "for name in [*exog, *endog]:\n",
    "    if name.split('.')[0] == 'L1':\n",
    "        namesplit = name.split('.')\n",
    "        data['D.'+name] = data[name] - data['L2.'+namesplit[-1]]\n",
    "    else:\n",
    "        data['D.'+name] = data[name] - data['L1.'+name]\n",
    "\n",
    "# # force balanced panel\n",
    "# data_dropna = data.dropna()\n",
    "# data_balanced = data_dropna.complete(ID,T)\n",
    "# data_balanced = data_balanced.sort_values([ID,T]).fillna(0).reset_index(drop=True)\n",
    "\n",
    "# generate Y and X\n",
    "data_balanced = data.dropna()\n",
    "_Y = np.array(data_balanced[exog]).reshape(-1,1)\n",
    "_X = data_balanced[endog]\n",
    "_X = np.array(_X).reshape(-1,_X.shape[1])\n",
    "_T = len(data_balanced[T].unique())\n",
    "_n = len(data_balanced[ID].unique())\n",
    "\n",
    "# build instrument\n",
    "data = data_balanced\n",
    "Xlist, Ylist, Zlist = [], [], []  ## CREATE LIST AND DO OPTIMIZATION\n",
    "IDlist = data[ID].unique()\n",
    "for i in IDlist:\n",
    "    data_i = data[data[ID]==i]\n",
    "    Z_it_list = []\n",
    "    for t,yr in enumerate(data_i[T].unique()):\n",
    "        if t <= 2:\n",
    "            pass\n",
    "        else:\n",
    "            Z_it = data_i[data_i[T]<=yr]\n",
    "#            Z_it = Z_it[[ID,'D.L1.debta']]\n",
    "            Z_it = Z_it[ID]\n",
    "            Z_it = np.array(Z_it.dropna()).reshape(1,-1)\n",
    "            Z_it_list.append(Z_it)\n",
    "    Z_i = block_diag(*Z_it_list)\n",
    "    Zlist.append(Z_i)\n",
    "#Z = np.vstack(Zlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cusip\n",
       "2     32\n",
       "3     32\n",
       "4     32\n",
       "5     32\n",
       "6     32"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_i = data[data[ID]==32]\n",
    "data_i[data_i[T]<=1976][[ID]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.2000e+01,  6.1514e-01,  3.2000e+01, -8.5610e-02,  3.2000e+01,\n",
       "        -5.8260e-02,  3.2000e+01,  2.9900e-02,  3.2000e+01, -2.0329e-01]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data_i[data_i[T]<=1976][[ID,'D.L1.debta']]).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip</th>\n",
       "      <th>year</th>\n",
       "      <th>debta</th>\n",
       "      <th>L1.debta</th>\n",
       "      <th>L2.debta</th>\n",
       "      <th>D.debta</th>\n",
       "      <th>D.L1.debta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>1972</td>\n",
       "      <td>0.57597</td>\n",
       "      <td>0.66158</td>\n",
       "      <td>0.04644</td>\n",
       "      <td>-0.08561</td>\n",
       "      <td>0.61514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>1973</td>\n",
       "      <td>0.51771</td>\n",
       "      <td>0.57597</td>\n",
       "      <td>0.66158</td>\n",
       "      <td>-0.05826</td>\n",
       "      <td>-0.08561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>1974</td>\n",
       "      <td>0.54761</td>\n",
       "      <td>0.51771</td>\n",
       "      <td>0.57597</td>\n",
       "      <td>0.02990</td>\n",
       "      <td>-0.05826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>1975</td>\n",
       "      <td>0.34432</td>\n",
       "      <td>0.54761</td>\n",
       "      <td>0.51771</td>\n",
       "      <td>-0.20329</td>\n",
       "      <td>0.02990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.55432</td>\n",
       "      <td>0.34432</td>\n",
       "      <td>0.54761</td>\n",
       "      <td>0.21000</td>\n",
       "      <td>-0.20329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27561</th>\n",
       "      <td>989845</td>\n",
       "      <td>1987</td>\n",
       "      <td>-0.00855</td>\n",
       "      <td>0.74615</td>\n",
       "      <td>0.39355</td>\n",
       "      <td>-0.75470</td>\n",
       "      <td>0.35260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27562</th>\n",
       "      <td>989845</td>\n",
       "      <td>1988</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00855</td>\n",
       "      <td>0.74615</td>\n",
       "      <td>0.00855</td>\n",
       "      <td>-0.75470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27563</th>\n",
       "      <td>989845</td>\n",
       "      <td>1989</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00855</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27564</th>\n",
       "      <td>989845</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.17137</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.17137</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27565</th>\n",
       "      <td>989845</td>\n",
       "      <td>1991</td>\n",
       "      <td>0.18676</td>\n",
       "      <td>0.17137</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01539</td>\n",
       "      <td>0.17137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23642 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cusip  year    debta  L1.debta  L2.debta  D.debta  D.L1.debta\n",
       "2          32  1972  0.57597   0.66158   0.04644 -0.08561     0.61514\n",
       "3          32  1973  0.51771   0.57597   0.66158 -0.05826    -0.08561\n",
       "4          32  1974  0.54761   0.51771   0.57597  0.02990    -0.05826\n",
       "5          32  1975  0.34432   0.54761   0.51771 -0.20329     0.02990\n",
       "6          32  1976  0.55432   0.34432   0.54761  0.21000    -0.20329\n",
       "...       ...   ...      ...       ...       ...      ...         ...\n",
       "27561  989845  1987 -0.00855   0.74615   0.39355 -0.75470     0.35260\n",
       "27562  989845  1988  0.00000  -0.00855   0.74615  0.00855    -0.75470\n",
       "27563  989845  1989  0.00000   0.00000  -0.00855  0.00000     0.00855\n",
       "27564  989845  1990  0.17137   0.00000   0.00000  0.17137     0.00000\n",
       "27565  989845  1991  0.18676   0.17137   0.00000  0.01539     0.17137\n",
       "\n",
       "[23642 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 465)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zlist[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 29)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape\n",
    "\n",
    "# Homoskedasticity\n",
    "D_i = toeplitz([-1,*np.zeros(_T-2)],[0,1,*np.zeros(_T-2)])\n",
    "H = D_i @ D_i.T\n",
    "H.shape\n",
    "#Omega1 = np.sum()\n",
    "#Omega1 = Z.T @ np.kron(np.eye(_n),H) @ Z\n",
    "#Omega1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = 3\n",
    "toeplitz([-1,*np.zeros(3-2)],[0,1,*np.zeros(3-2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denom = (_X.T @ Z @ np.linalg.inv(Omega) @ Z.T @ _X)\n",
    "nom = (_X.T @ Z @ np.linalg.inv(Omega) @ Z.T @ _Y)\n",
    "gmm = np.linalg.inv(denom)@nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zlist[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[['cusip','year','debta','L1.debta','L2.debta', 'D.debta', 'D.L1.debta']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data_dropna\n",
    "df_balanced = df.complete('cusip','year')\n",
    "df_balanced.sort_values(['cusip','year']).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.complete(('ID', 'City', 'State'), 'Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_diag(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['cusip','year','debta','L1.debta','L2.debta', 'D.debta', 'D.L1.debta']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
