{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6488e7ef",
   "metadata": {},
   "source": [
    "# Problem Set 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68f46a0",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f335af",
   "metadata": {},
   "source": [
    "Continuing with the model (4), we numerically investigate the performance of various estimators designed for static panel data models, namely, $\\hat\\beta_{n,\\mathrm{POLS}}$, $\\hat\\beta_{n,\\mathrm{FE}}$, $\\hat\\beta_{n,\\mathrm{FD}}$, and the first differenced estimator using $Y_{i,t-2}$ as instrument (i.e., the IV estimator of $\\beta_0$ for the first-differenced equation using $Y_{i,t-2}$ as instrument). First, for each triple $(n,T,\\beta_0)$ to be specified shortly, obtain the sample as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce28ac0",
   "metadata": {},
   "source": [
    "1. Simulate $\\alpha_i\\overset{\\mathrm{iid}}{\\sim} N(0,1)$ and $\\epsilon_i\\overset{\\mathrm{iid}}{\\sim} N(0,1)$.\n",
    "\n",
    "2. Generate $Y_{i0}$ according to $Y_{i0}=0.5\\alpha_i + \\epsilon_i$.\n",
    "\n",
    "3. Generate $Y_{it}$ according to (4) with $V_{it}\\overset{\\mathrm{iid}}{\\sim} N(0,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357cdac8",
   "metadata": {},
   "source": [
    "You may then compute the aforementioned estimators with the generated sample. Repeat the above steps $1000$ times, let $\\hat\\beta^{(r)}$ be the estimate based on the $i$th replication (for a particular estimator), and then the finite sample bias, standard error and root mean squared error are computed as follows:\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathrm{Bias}(\\hat\\beta)&=\\frac{1}{1000}\\sum_{r=1}^{1000}\\hat\\beta^{(r)} - \\beta_0~,\\\\\n",
    "    \\mathrm{SE}(\\hat\\beta)&=\\{\\frac{1}{1000}\\sum_{r=1}^{1000}(\\hat\\beta^{(r)}-\\frac{1}{1000}\\sum_{r=1}^{1000}\\hat\\beta^{(r)})^2 \\}^{1/2}~,\\\\\n",
    "    \\mathrm{RMSE} (\\hat\\beta) & = \\{[\\mathrm{Bias}(\\hat\\beta)]^2 + [\\mathrm{SE}(\\hat\\beta)]^2\\}^{1/2}~.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aae756",
   "metadata": {},
   "source": [
    "1. Let $n=100$ and $T=6$. Graph the bias, se and rmse of each estimator as functions of $\\beta_0\\in\\{0,0.25,0.5,0.75,1\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fbb8a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import statsmodels.api as sm\n",
    "import linearmodels.panel as lm\n",
    "\n",
    "def DGP(n,T,b0 = 0.5):\n",
    "    a = np.random.normal(0,1,n)\n",
    "    e = np.random.normal(0,1,n)\n",
    "    \n",
    "    Y0 = 0.5*a + e  # n by 1\n",
    "    Ymatrix = np.zeros([n, T])  # n by T then stack\n",
    "    Xmatrix = np.zeros([n, T])\n",
    "    for t in range(T):\n",
    "        V = np.random.normal(0,1,n)\n",
    "        if t == 0:\n",
    "            Y1 = b0*Y0 + a + V\n",
    "            Ymatrix[:,t] = Y1\n",
    "            Xmatrix[:,t] = Y0\n",
    "        else:\n",
    "            Y0 = Ymatrix[:,t-1]\n",
    "            Y1 = b0*Y0 + a + V\n",
    "            Ymatrix[:,t] = Y1\n",
    "            Xmatrix[:,t] = Y0\n",
    "    \n",
    "    Y = Ymatrix.reshape(-1)\n",
    "    X = Xmatrix.reshape(-1)\n",
    "    i = np.kron(np.array([i+1 for i in range(n)]).reshape(n,1), np.ones(T).reshape(T,1)).reshape(-1)\n",
    "    t = np.kron(np.ones(n).reshape(n,1), np.array([i+1 for i in range(T)]).reshape(T,1)).reshape(-1)\n",
    "    df = pd.DataFrame({'i':i,'t':t,'Y':Y,'X':X})\n",
    "    \n",
    "    return df\n",
    "\n",
    "def test_DGP(n,T,b0 = 0.5):\n",
    "    \"\"\"\n",
    "    X is exogenous\n",
    "    \"\"\"\n",
    "    a = np.random.normal(0,1,n)\n",
    "    e = np.random.normal(0,1,n)\n",
    "    \n",
    "    Y0 = 0.5*a + e  # n by 1\n",
    "    Ymatrix = np.zeros([n, T])  # n by T -> stack using reshape.\n",
    "    Xmatrix = np.zeros([n, T])\n",
    "    for t in range(T):\n",
    "        V = np.random.normal(0,1,n)\n",
    "        X = np.random.normal(0,1,n)\n",
    "        Y = b0 * X + a + V        \n",
    "        Ymatrix[:,t] = Y\n",
    "        Xmatrix[:,t] = X\n",
    "    Y = Ymatrix.reshape(-1)\n",
    "    X = Xmatrix.reshape(-1)\n",
    "    i = np.kron(np.array([i+1 for i in range(n)]).reshape(n,1), np.ones(T).reshape(T,1)).reshape(-1)\n",
    "    t = np.kron(np.ones(n).reshape(n,1), np.array([i+1 for i in range(T)]).reshape(T,1)).reshape(-1)\n",
    "    df = pd.DataFrame({'i':i,'t':t,'Y':Y,'X':X})\n",
    "    \n",
    "    return df\n",
    "\n",
    "def my_OLS(Y,X):\n",
    "    beta = np.linalg.inv(X.T@X) @ (X.T@Y)\n",
    "    \n",
    "    return beta[0]\n",
    "\n",
    "def my_FE(Y,X,T):\n",
    "    nT, k = X.shape\n",
    "    n = int(nT/T)\n",
    "    Qi = np.eye(T) - (np.ones(T).reshape(T,1) @ np.ones(T).reshape(1,T))/T\n",
    "    Q = np.kron(np.eye(n), Qi)\n",
    "    \n",
    "    beta = np.linalg.inv(X.T @ Q @ X) @ (X.T @ Q @ Y)\n",
    "    \n",
    "    return beta[0]\n",
    "\n",
    "def my_FD(Y,X,T):\n",
    "    nT,k = X.shape\n",
    "    n = int(nT/T)\n",
    "    \n",
    "    toep = toeplitz([-1,*np.zeros(T-2)],[0,1,*np.zeros(T-2)])\n",
    "    dY = np.kron(np.eye(n),toep) @ Y\n",
    "    dX = np.kron(np.eye(n),toep) @ X\n",
    "    \n",
    "    beta = my_OLS(dY,dX)\n",
    "    return beta[0]\n",
    "\n",
    "def my_FD_IV(Y,X,T, method=\"2SLS\"):\n",
    "    nT,k = X.shape\n",
    "    n = int(nT/T)\n",
    "    \n",
    "    toep = toeplitz([-1,*np.zeros(T-2)],[0,1,*np.zeros(T-2)])[1:,:]\n",
    "    dY = np.kron(np.eye(n),toep) @ Y\n",
    "    dX = np.kron(np.eye(n),toep) @ X\n",
    "    \n",
    "    sel = np.eye(T)[:-2,:]\n",
    "    Z = np.kron(np.eye(n),sel) @ Y\n",
    "    \n",
    "#     Y_nbyT = Y.reshape(n, T)  # [Y_{t=1}, Y_{t=2}, ..., Y_{t=T}]\n",
    "#     X_nbyT = X.reshape(n, T)\n",
    "#     Y_nbyT_lag = np.column_stack([np.zeros(n), Y_nbyT[:,:-1]])  # [0,t=2-1,t=3-2,...]\n",
    "#     X_nbyT_lag = np.column_stack([np.zeros(n), X_nbyT[:,:-1]])\n",
    "    \n",
    "#     dY = (Y_nbyT-Y_nbyT_lag)[:,2:].reshape([n*(T-2),1])  # vec[Y_{t=3-2}, Y_{t=4-3}, ...]\n",
    "#     dX = (X_nbyT-X_nbyT_lag)[:,2:].reshape([n*(T-2),k])  # vec[Y_{t=2-1}, Y_{t=3-2}, ...]\n",
    "#     iv = Y_nbyT[:,:-2].reshape([n*(T-2),1])  # vec[Y_{t=1}, Y_{t=2}, ..., Y_{t=T-2}]\n",
    "    \n",
    "    # 2SLS\n",
    "    if method == \"2SLS\":\n",
    "        dXhat = Z @ (np.linalg.inv(Z.T@Z) @ (Z.T@dX))\n",
    "        beta = my_OLS(dY,dXhat)\n",
    "    if method == \"IV\":\n",
    "        nom = dX.T@Z @ np.linalg.inv(Z.T@Z) @ Z.T@dY\n",
    "        denom = dX.T@Z @ np.linalg.inv(Z.T@Z) @ Z.T@dX\n",
    "        beta = np.linalg.inv(denom) @ nom\n",
    "        beta = beta[0]\n",
    "    if method == \"IV_just\":\n",
    "        beta = np.linalg.inv(Z.T@dX) @ Z.T@dY\n",
    "\n",
    "    return beta\n",
    "\n",
    "def simulation_Q3(n,T,M=1000,test=False):\n",
    "    res = []\n",
    "    for b0 in [0, 0.25, 0.5, 0.75, 1]:\n",
    "        res_POLS = np.zeros(M)\n",
    "        res_FE = np.zeros(M)\n",
    "        res_FD = np.zeros(M)\n",
    "        res_FD_IV = np.zeros(M)\n",
    "    \n",
    "        for m in range(M):\n",
    "            if test is True:\n",
    "                df = test_DGP(n=n,T=T,b0=b0)\n",
    "                Y = np.array(df.Y).reshape(n*T,1)\n",
    "                X = np.array(df.X).reshape(n*T,1)\n",
    "            else:\n",
    "                df = DGP(n=n,T=T,b0=b0)\n",
    "                Y = np.array(df.Y).reshape(n*T,1)\n",
    "                X = np.array(df.X).reshape(n*T,1)\n",
    "            res_POLS[m] = my_OLS(Y,X)\n",
    "            res_FE[m] = my_FE(Y,X,T=T)\n",
    "            res_FD[m] = my_FD(Y,X,T=T)\n",
    "            res_FD_IV[m] = my_FD_IV(Y,X,T=T,method=\"2SLS\")\n",
    "    \n",
    "        res.append({\"POLS\":res_POLS, \"FE\":res_FE,\"FD\":res_FD,\"FD_IV\":res_FD_IV})\n",
    "    return res\n",
    "\n",
    "def figure_Q3(res, n, T, save=False):\n",
    "    b0 = np.array([0,0.25,0.5,0.75,1.])\n",
    "    result_000 = res[0]\n",
    "    \n",
    "    result_000_POLS = result_000[\"POLS\"]\n",
    "    \n",
    "    result_025 = res[1]\n",
    "    result_050 = res[2]\n",
    "    result_075 = res[3]\n",
    "    result_100 = res[4]\n",
    "          \n",
    "    bias_POLS = [res[i][\"POLS\"].mean() - b0[i] for i in range(len(res))]\n",
    "    bias_FE = [res[i][\"FE\"].mean() - b0[i] for i in range(len(res))]\n",
    "    bias_FD = [res[i][\"FD\"].mean() - b0[i] for i in range(len(res))]\n",
    "    bias_FD_IV = [res[i][\"FD_IV\"].mean() - b0[i] for i in range(len(res))]\n",
    "\n",
    "    std_POLS = [res[i][\"POLS\"].std() for i in range(len(res))]\n",
    "    std_FE = [res[i][\"FE\"].std() for i in range(len(res))]\n",
    "    std_FD = [res[i][\"FD\"].std() for i in range(len(res))]\n",
    "    std_FD_IV = [res[i][\"FD_IV\"].std() for i in range(len(res))]\n",
    "    \n",
    "    rmse_POLS = [np.sqrt(bias_POLS[i]**2 + std_POLS[i]**2) for i in range(len(res))]\n",
    "    rmse_FE = [np.sqrt(bias_FE[i]**2 + std_FE[i]**2) for i in range(len(res))]\n",
    "    rmse_FD = [np.sqrt(bias_FD[i]**2 + std_FD[i]**2) for i in range(len(res))]\n",
    "    rmse_FD_IV = [np.sqrt(bias_FD_IV[i]**2 + std_FD_IV[i]**2) for i in range(len(res))]\n",
    "    \n",
    "    fig, ax = plt.subplots(1,3,figsize = (21,4))\n",
    "    \n",
    "    ax[0].plot(b0, bias_POLS)\n",
    "    ax[0].plot(b0, bias_FE)\n",
    "    ax[0].plot(b0, bias_FD)\n",
    "    ax[0].plot(b0, bias_FD_IV)\n",
    "    ax[0].axhline(0, color='black')\n",
    "    ax[0].legend([\"POLS\", \"FE\", \"FD\", \"FD_IV\"])\n",
    "    ax[0].set_xlabel('b0')\n",
    "    ax[0].set_title(\"Bias of simulation (n={},T={})\".format(n,T))\n",
    "\n",
    "    ax[1].plot(b0, std_POLS)\n",
    "    ax[1].plot(b0, std_FE)\n",
    "    ax[1].plot(b0, std_FD)\n",
    "    ax[1].plot(b0, std_FD_IV)\n",
    "    ax[1].legend([\"POLS\", \"FE\", \"FD\", \"FD_IV\"])\n",
    "    ax[1].set_xlabel('b0')\n",
    "    ax[1].set_title(\"SE of simulation (n={},T={})\".format(n,T))\n",
    "\n",
    "    ax[2].plot(b0, rmse_POLS)\n",
    "    ax[2].plot(b0, rmse_FE)\n",
    "    ax[2].plot(b0, rmse_FD)\n",
    "    ax[2].plot(b0, rmse_FD_IV)\n",
    "    ax[2].legend([\"POLS\", \"FE\", \"FD\", \"FD_IV\"])\n",
    "    ax[2].set_xlabel('b0')\n",
    "    ax[2].set_title(\"RMSE of simulation (n={},T={})\".format(n,T))\n",
    "    \n",
    "    fig.savefig('fig_n{}_T{}.jpg'.format(n,T), dpi=80)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db22a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_n100_T6 = simulation_Q3(n=100,T=6,M=1000)\n",
    "fig_n100_T6 = figure_Q3(results_n100_T6, n=100,T=6, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16717523",
   "metadata": {},
   "source": [
    "2 . Repeat part (1) with $(n,T)=(100,3)$ and $(n,T)=(100,9)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934f1707",
   "metadata": {},
   "outputs": [],
   "source": [
    "n,T = 100,3\n",
    "results_n100_T3 = simulation_Q3(n=n,T=T,M=1000)\n",
    "fig_n100_T3 = figure_Q3(results_n100_T3, n=n,T=T, save=True)\n",
    "\n",
    "n,T = 100,9\n",
    "results_n100_T9 = simulation_Q3(n=n,T=T,M=1000)\n",
    "fig_n100_T9 = figure_Q3(results_n100_T9, n=n,T=T, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a1c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydynpd import regression\n",
    "_data = test_DGP(n=100,T=6,b0=0.5)\n",
    "command_str='Y L1.Y  | gmm(Y, 2:.) | nolevel'\n",
    "mydpd = regression.abond(command_str, _data, ['i', 't'])\n",
    "\n",
    "mydpd.models[0].regression_table.coefficient[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2630905",
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = DGP(100,6,0)\n",
    "_Y = np.array(_data.Y).reshape(600,1)\n",
    "_X = np.array(_data.X).reshape(600,1)\n",
    "\n",
    "np.column_stack([_Y,_X])\n",
    "\n",
    "my_FD_IV(_Y,_X,T=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1b5181",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8120204b",
   "metadata": {},
   "source": [
    "Do Exercise 17.17(a) in Hansen (2022). You will need the formula (17.93) in Hansen (2022) (see the pdf file in Canvas) for the clustered standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96c6bc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip</th>\n",
       "      <th>year</th>\n",
       "      <th>pstar</th>\n",
       "      <th>z0</th>\n",
       "      <th>pricef</th>\n",
       "      <th>divf</th>\n",
       "      <th>rnda</th>\n",
       "      <th>adva</th>\n",
       "      <th>fyr</th>\n",
       "      <th>ardsic</th>\n",
       "      <th>...</th>\n",
       "      <th>debta</th>\n",
       "      <th>sales</th>\n",
       "      <th>netcap</th>\n",
       "      <th>earnsh</th>\n",
       "      <th>nyseamex</th>\n",
       "      <th>h0</th>\n",
       "      <th>h1</th>\n",
       "      <th>vala</th>\n",
       "      <th>oneper</th>\n",
       "      <th>sharef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>1970</td>\n",
       "      <td>4.45946</td>\n",
       "      <td>31.21624</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04644</td>\n",
       "      <td>45.33499</td>\n",
       "      <td>22.64583</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1</td>\n",
       "      <td>53.51015</td>\n",
       "      <td>19.18859</td>\n",
       "      <td>1.17240</td>\n",
       "      <td>-0.48167</td>\n",
       "      <td>2655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>1971</td>\n",
       "      <td>5.18880</td>\n",
       "      <td>31.13281</td>\n",
       "      <td>5.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.66158</td>\n",
       "      <td>47.03299</td>\n",
       "      <td>19.28410</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>1</td>\n",
       "      <td>54.77370</td>\n",
       "      <td>16.40725</td>\n",
       "      <td>0.79165</td>\n",
       "      <td>-0.19062</td>\n",
       "      <td>2655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>1972</td>\n",
       "      <td>5.66540</td>\n",
       "      <td>28.32700</td>\n",
       "      <td>5.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00543</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57597</td>\n",
       "      <td>34.36200</td>\n",
       "      <td>14.90893</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>52.25176</td>\n",
       "      <td>12.75835</td>\n",
       "      <td>0.91267</td>\n",
       "      <td>-0.694</td>\n",
       "      <td>2655.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cusip  year    pstar        z0  pricef  divf  rnda     adva  fyr  ardsic  \\\n",
       "0     32  1970  4.45946  31.21624  10.000   0.0   0.0  0.00000   12      11   \n",
       "1     32  1971  5.18880  31.13281   5.750   0.0   0.0  0.00000   12      11   \n",
       "2     32  1972  5.66540  28.32700   5.125   0.0   0.0  0.00543   12      11   \n",
       "\n",
       "   ...    debta     sales    netcap  earnsh  nyseamex        h0        h1  \\\n",
       "0  ...  0.04644  45.33499  22.64583    0.17         1  53.51015  19.18859   \n",
       "1  ...  0.66158  47.03299  19.28410   -0.65         1  54.77370  16.40725   \n",
       "2  ...  0.57597  34.36200  14.90893    0.72         1  52.25176  12.75835   \n",
       "\n",
       "      vala    oneper  sharef  \n",
       "0  1.17240  -0.48167  2655.0  \n",
       "1  0.79165  -0.19062  2655.0  \n",
       "2  0.91267    -0.694  2655.0  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "import pandas as pd\n",
    "from pydynpd import regression\n",
    "import janitor\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "file = os.path.join(os.getcwd(),\"..\",\"Econometrics Data\",\"Invest1993\",\"Invest1993.txt\")\n",
    "df = pd.read_csv(file, sep='\\t')\n",
    "df.head(3)\n",
    "#df.year.unique().max() - df.year.unique().min() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45134d7b-015a-41aa-8520-26001059f834",
   "metadata": {},
   "source": [
    "$$\n",
    "D_{it} = \\alpha D_{i,t-1} + u_i + \\epsilon_{it}\n",
    "$$\n",
    "\n",
    "(a) Estimate the model using Arellano-Bond twostep GMM with clustered se."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "705bf659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dynamic panel-data estimation, one-step difference GMM\n",
      " Group variable: cusip                             Number of obs = 23642    \n",
      " Time variable: year                               Min obs per group: 3     \n",
      " Number of instruments = 465                       Max obs per group: 30    \n",
      " Number of groups = 1962                           Avg obs per group: 12.05 \n",
      "+----------+-----------+---------------------+-----------+-----------+-----+\n",
      "|  debta   |   coef.   | Corrected Std. Err. |     z     |   P>|z|   |     |\n",
      "+----------+-----------+---------------------+-----------+-----------+-----+\n",
      "| L1.debta | 0.5498328 |      0.0603789      | 9.1063747 | 0.0000000 | *** |\n",
      "+----------+-----------+---------------------+-----------+-----------+-----+\n",
      "Hansen test of overid. restrictions: chi(464) = 510.883 Prob > Chi2 = 0.065\n",
      "Arellano-Bond test for AR(1) in first differences: z = -5.09 Pr > z =0.000\n",
      "Arellano-Bond test for AR(2) in first differences: z = 1.24 Pr > z =0.216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "command_str='debta L1.debta  | gmm(debta, 2:.) | onestep nolevel'\n",
    "mydpd = regression.abond(command_str, df, ['cusip', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9cbecdf2-f1e3-4428-b814-5640b8cfcce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file, sep='\\t')\n",
    "\n",
    "# def my_Arellano_Bond(data):\n",
    "exog = 'debta'\n",
    "endog = ['L1.debta']\n",
    "iv = ['L2.debta']\n",
    "ID = 'cusip'\n",
    "T = 'year'\n",
    "\n",
    "# df = DGP(n=1000,T=10,b0=1)\n",
    "# exog = 'Y'\n",
    "# endog = ['L1.Y']\n",
    "# iv = ['L2.Y']\n",
    "# ID = 'i'\n",
    "# T = 't'\n",
    "\n",
    "data = df[[ID,T,exog]].copy()\n",
    "data = data.sort_values([ID,T])\n",
    "Tmax = np.max(data.groupby(ID)[T].count())\n",
    "\n",
    "# generate lagged variables\n",
    "for name in [*endog,*iv]:\n",
    "    if name.split('.')[0] == 'L1':  # assume T increases by 1\n",
    "        data[name] = data[[ID, name.split('.')[-1]]].groupby(ID).shift(1)\n",
    "    if name.split('.')[0] == 'L2':\n",
    "        data[name] = data[[ID, name.split('.')[-1]]].groupby(ID).shift(2)\n",
    "        \n",
    "# generate differenced varialbes\n",
    "for name in [exog, *endog]:\n",
    "    if name.split('.')[0] == 'L1':\n",
    "        namesplit = name.split('.')\n",
    "        data['D.'+name] = data[name] - data['L2.'+namesplit[-1]]\n",
    "    else:\n",
    "        data['D.'+name] = data[name] - data['L1.'+name]\n",
    "\n",
    "# # force balanced panel\n",
    "data_dropna = data.dropna()\n",
    "data_balanced = data_dropna.complete(ID,T)\n",
    "data_balanced = data_balanced.sort_values([ID,T]).fillna(0).reset_index(drop=True)\n",
    "\n",
    "# generate Y and X\n",
    "_Y = np.array(data_balanced[exog]).reshape(-1,1)\n",
    "_X = data_balanced[endog]\n",
    "_X = np.array(_X).reshape(-1,_X.shape[1])\n",
    "_T = len(data_balanced[T].unique())\n",
    "_n = len(data_balanced[ID].unique())\n",
    "\n",
    "# build instrument\n",
    "data = data_balanced\n",
    "Xlist, Ylist, Zlist = [], [], []\n",
    "IDlist = data[ID].unique()\n",
    "for i in IDlist:\n",
    "    data_i = data[data[ID]==i]\n",
    "    Ylist.append(np.array(data_i['L1.'+exog]).reshape(-1,1))\n",
    "    Xlist.append(np.array(data_i['L2.'+exog]).reshape(-1,1))\n",
    "    Z_it_list = []\n",
    "    for t,yr in enumerate(data_i[T].unique()):\n",
    "        Z_it = data_i[data_i[T]<=yr]\n",
    "        Z_it = Z_it[iv]\n",
    "        Z_it = np.array(Z_it.dropna()).reshape(1,-1)\n",
    "        Z_it_list.append(Z_it)\n",
    "    Z_i = block_diag(*Z_it_list)\n",
    "    Zlist.append(Z_i)\n",
    "Z = np.vstack(Zlist)\n",
    "\n",
    "# one-step Arellano-Bond GMM estimator\n",
    "D_i = toeplitz([-1,*np.zeros(_T-1)],[0,1,*np.zeros(_T-1)])\n",
    "H = D_i @ D_i.T\n",
    "Omega1 = Z.T @ np.kron(np.eye(_n), H) @ Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cac3ff70-4205-4638-a6e9-9c28f5f4099e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98629719]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Omega1inv = np.linalg.inv(Omega1)\n",
    "denom = _X.T @ Z @ Omega1inv @ Z.T @ _X\n",
    "nom = _X.T @ Z @ Omega1inv @ Z.T @ _Y\n",
    "alpha_1SAB = np.linalg.solve(denom, nom)\n",
    "alpha_1SAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "04147384-93cd-4bd0-8d50-d49a9a39b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classical covariance matrix estimator\n",
    "res_1SAB = _Y - _X @ alpha_1SAB\n",
    "Omega2 = Z.T @ res_1SAB @ res_1SAB.T @ Z\n",
    "try:\n",
    "    Omega2inv = np.linalg.inv(Omega2)\n",
    "except:\n",
    "    Omega2inv = np.linalg.pinv(Omega2)\n",
    "# A = _X.T @ Z @ Omega1inv @ Z.T @ _X\n",
    "# B = _X.T @ Z @ Omega1inv @ Z.T @ Omega2inv @ Z @ Omega1inv @ Z.T @ _X\n",
    "# V_1hat = np.linalg.inv(A) @ B @ np.linalg.inv(A)\n",
    "# V_1hat0 = res_1SAB.std()**2 @ np.linalg.inv(_X.T@Z@Omega1inv@Z.T@ _X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "361dfd49-64fd-433e-9505-f8715f26805d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70047774]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two-step Arellano-Bond GMM estimator\n",
    "denom = _X.T @ Z @ Omega2inv @ Z.T @ _X\n",
    "nom = _X.T @ Z @ Omega2inv @ Z.T @ _Y\n",
    "alpha_2SAB = np.linalg.solve(denom, nom)\n",
    "alpha_2SAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "24965b7c-89d5-4b67-8c22-e8fb85765f5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha_2SAB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-586c2ae1e146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# cluster-robust estimator of 2SAB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mres_2SAB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Y\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0m_X\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0malpha_2SAB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mOmega3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mres_2SAB\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mres_2SAB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mOmega3inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOmega3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mOmega2inv\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0m_X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alpha_2SAB' is not defined"
     ]
    }
   ],
   "source": [
    "# cluster-robust estimator of 2SAB\n",
    "res_2SAB = _Y - _X @ alpha_2SAB\n",
    "Omega3 = Z.T @ res_2SAB @ res_2SAB.T @ Z\n",
    "Omega3inv = np.linalg.inv(Omega3)\n",
    "A = _X.T @ Z @ Omega2inv @ Z.T @ _X\n",
    "B = _X.T @ Z @ Omega2inv @ Z.T @ Omega3inv @ Z @ Omega2inv @ Z.T @ _X\n",
    "V_2hat = np.linalg.inv(A) @ B @ np.linalg.inv(A)\n",
    "V_2tilde = np.linalg.inv(_X.T@Z@Omega2inv@Z.T@X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c3d07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
